{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distinquishing between pooping dogs and non-pooping dogs using machine learning\n",
    "\n",
    "### Table of contents\n",
    "1. [Dataset](#introduction)\n",
    "2. [Labeling with Amazon SageMaker Ground Truth](#groundtruth)\n",
    "3. [Reviewing labeling results](#review)\n",
    "4. [Training an Object Detection model](#training)\n",
    "5. [Review of Training Results](#review_training)\n",
    "6. [Model Tuning](#model_tuning)\n",
    "7. [Cleanup](#cleanup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"introduction\"></a>\n",
    "## Dataset\n",
    "Our dataset is sourced from popular search engines. The images need to be synced from the s3 bucket to the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'deeplens-sagemaker-poopinator'\n",
    "PREFIX = 'working' # root path working space\n",
    "labeling_job_name = 'dog-obj2'\n",
    "training_job_name = 'poopinator-detection-resnet'\n",
    "local_working_dir = 'working'\n",
    "local_manifest_dir = local_working_dir + '/manifests'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync s3://$BUCKET/images images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling with SageMaker Ground Truth <a name=\"groundtruth\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a Ground Truth job to label our images. Once the labeling job is complete we can proceed with the next section of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviewing labeling results\n",
    "<a name=\"reviewing\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the labeling job is complete we can review the results to verfiy the images were labeled correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we plot the annotated images. We display the images from the notebook and draw the bounding boxes from the labeling job on top of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "client = boto3.client('sagemaker')\n",
    "\n",
    "s3_output = client.describe_labeling_job(LabelingJobName=labeling_job_name)['OutputConfig']['S3OutputPath'] + labeling_job_name\n",
    "augmented_manifest_url = f'{s3_output}/manifests/output/output.manifest'\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "try:\n",
    "    os.makedirs(local_manifest_dir, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    shutil.rmtree(local_manifest_dir)\n",
    "\n",
    "augmented_manifest_file = local_manifest_dir + '/output.manifest'\n",
    "!aws s3 cp $augmented_manifest_url $augmented_manifest_file\n",
    "!head -3 $augmented_manifest_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from itertools import cycle\n",
    "\n",
    "def show_annotated_image(img_path, bboxes, prec):\n",
    "    im = np.array(Image.open(img_path), dtype=np.uint8)\n",
    "    \n",
    "    # Create figure and axes\n",
    "    fig,ax = plt.subplots(1)\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(im)\n",
    "\n",
    "    colors = cycle(['r', 'o', 'b', 'g', 'c', 'm', 'k', 'w'])\n",
    "    \n",
    "    right = .1\n",
    "    bottom = .9\n",
    "    \n",
    "    for bbox in bboxes:\n",
    "        \n",
    "        if bbox['class_id'] == 0:\n",
    "            class_id = 'pooping'\n",
    "            text_color = 'red'\n",
    "        elif bbox['class_id'] == 1:\n",
    "            class_id = 'not_pooping'\n",
    "            text_color = 'orange'\n",
    "            \n",
    "        # Create a Rectangle patch\n",
    "        rect = patches.Rectangle((bbox['left'],bbox['top']),bbox['width'],bbox['height'],linewidth=1,edgecolor=text_color,facecolor='none')\n",
    "     \n",
    "        # Add the patch to the Axes\n",
    "        ax.add_patch(rect)\n",
    "        if float(prec) == 1:\n",
    "            ax.text(right, bottom, class_id,\n",
    "            horizontalalignment='left',\n",
    "            verticalalignment='top',\n",
    "            color=text_color,\n",
    "            backgroundcolor='white',\n",
    "            transform=ax.transAxes)\n",
    "        elif float(prec) < 1:\n",
    "            ax.text(right, bottom, class_id + '\\n' + prec + '%',\n",
    "            horizontalalignment='left',\n",
    "            verticalalignment='top',\n",
    "            color=text_color,\n",
    "            backgroundcolor='white',\n",
    "            transform=ax.transAxes)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the augmented manifest line by line and display the first 10 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The PIP install stuff only needs to run once, it should probably be moved to a Lifecycle script ###\n",
    "!pip -q install --upgrade pip\n",
    "!pip -q install jsonlines\n",
    "import jsonlines\n",
    "from itertools import islice\n",
    "    \n",
    "with jsonlines.open(augmented_manifest_file, 'r') as reader:\n",
    "    for desc in islice(reader, 10):\n",
    "        img_url = desc['source-ref']\n",
    "        img_file = \"images/source/\" + os.path.basename(img_url)\n",
    "        file_exists = os.path.isfile(img_file)\n",
    "        bboxes = desc[labeling_job_name]['annotations']\n",
    "        show_annotated_image(img_file, bboxes, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='training'></a>\n",
    "## Training an Object Detection Model\n",
    "We are now ready to use the labeled dataset in order to train a Machine Learning model using the SageMaker [built-in Object Detection algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/object-detection.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "augmented_manifest_filename_output = local_manifest_dir + '/output.manifest'\n",
    "\n",
    "with jsonlines.open(augmented_manifest_filename_output, 'r') as reader:\n",
    "    lines = list(reader)\n",
    "    # Shuffle data in place.\n",
    "    np.random.shuffle(lines)\n",
    "    \n",
    "dataset_size = len(lines)\n",
    "num_training_samples = round(dataset_size*0.9)\n",
    "\n",
    "train_data = lines[:num_training_samples]\n",
    "validation_data = lines[num_training_samples:]\n",
    "\n",
    "augmented_manifest_filename_train = local_manifest_dir + '/train.manifest'\n",
    "\n",
    "with open(augmented_manifest_filename_train, 'w') as f:\n",
    "    for line in train_data:\n",
    "        f.write(json.dumps(line))\n",
    "        f.write('\\n')\n",
    "\n",
    "augmented_manifest_filename_validation = local_manifest_dir + '/validation.manifest'\n",
    "\n",
    "with open(augmented_manifest_filename_validation, 'w') as f:\n",
    "    for line in validation_data:\n",
    "        f.write(json.dumps(line))\n",
    "        f.write('\\n')\n",
    "        \n",
    "print(f'training samples: {num_training_samples}, validation samples: {len(lines)-num_training_samples}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's upload the two manifest files to S3 in preparation for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfx_training = PREFIX + '/training' if PREFIX else 'training'\n",
    "# Defines paths for use in the training job request.\n",
    "s3_train_data_path = 's3://{}/{}/{}'.format(BUCKET, pfx_training, augmented_manifest_filename_train)\n",
    "s3_validation_data_path = 's3://{}/{}/{}'.format(BUCKET, pfx_training, augmented_manifest_filename_validation)\n",
    "\n",
    "!aws s3 cp $augmented_manifest_filename_train s3://$BUCKET/$pfx_training/\n",
    "!aws s3 cp $augmented_manifest_filename_validation s3://$BUCKET/$pfx_training/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to start the training job in the SageMaker console. Notebook code option below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "training_image = sagemaker.amazon.amazon_estimator.get_image_uri(\n",
    "    boto3.Session().region_name, 'object-detection', repo_version='latest')\n",
    "s3_output_path = 's3://{}/{}/output'.format(BUCKET, pfx_training)\n",
    "\n",
    "training_params = \\\n",
    "    {\n",
    "        \"AlgorithmSpecification\": {\n",
    "            # NB. This is one of the named constants defined in the first cell.\n",
    "            \"TrainingImage\": training_image,\n",
    "            \"TrainingInputMode\": \"Pipe\"\n",
    "        },\n",
    "        \"RoleArn\": role,\n",
    "        \"OutputDataConfig\": {\n",
    "            \"S3OutputPath\": s3_output_path\n",
    "        },\n",
    "        \"ResourceConfig\": {\n",
    "            \"InstanceCount\": 1,\n",
    "            \"InstanceType\": \"ml.p2.xlarge\",\n",
    "            \"VolumeSizeInGB\": 50\n",
    "        },\n",
    "        \"TrainingJobName\": training_job_name,\n",
    "        \"HyperParameters\": {  # NB. These hyperparameters are at the user's discretion and are beyond the scope of this demo.\n",
    "            \"base_network\": \"resnet-50\",\n",
    "            \"use_pretrained_model\": \"1\",\n",
    "            \"num_classes\": \"2\",\n",
    "            \"mini_batch_size\": \"1\",\n",
    "            \"epochs\": \"100\",\n",
    "            \"learning_rate\": \"0.001\",\n",
    "            \"lr_scheduler_step\": \"\",\n",
    "            \"lr_scheduler_factor\": \"0.1\",\n",
    "            \"optimizer\": \"sgd\",\n",
    "            \"momentum\": \"0.9\",\n",
    "            \"weight_decay\": \"0.0005\",\n",
    "            \"overlap_threshold\": \"0.5\",\n",
    "            \"nms_threshold\": \"0.45\",\n",
    "            \"image_shape\": \"300\",\n",
    "            \"label_width\": \"350\",\n",
    "            \"num_training_samples\": str(num_training_samples)\n",
    "        },\n",
    "        \"StoppingCondition\": {\n",
    "            \"MaxRuntimeInSeconds\": 86400\n",
    "        },\n",
    "        \"InputDataConfig\": [\n",
    "            {\n",
    "                \"ChannelName\": \"train\",\n",
    "                \"DataSource\": {\n",
    "                    \"S3DataSource\": {\n",
    "                        \"S3DataType\": \"AugmentedManifestFile\",  # NB. Augmented Manifest\n",
    "                        \"S3Uri\": s3_train_data_path,\n",
    "                        \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                        # NB. This must correspond to the JSON field names in your augmented manifest.\n",
    "                        \"AttributeNames\": ['source-ref', labeling_job_name]\n",
    "                    }\n",
    "                },\n",
    "                \"ContentType\": \"application/x-recordio\",\n",
    "                \"RecordWrapperType\": \"RecordIO\",\n",
    "                \"CompressionType\": \"None\"\n",
    "            },\n",
    "            {\n",
    "                \"ChannelName\": \"validation\",\n",
    "                \"DataSource\": {\n",
    "                    \"S3DataSource\": {\n",
    "                        \"S3DataType\": \"AugmentedManifestFile\",  # NB. Augmented Manifest\n",
    "                        \"S3Uri\": s3_validation_data_path,\n",
    "                        \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                        # NB. This must correspond to the JSON field names in your augmented manifest.\n",
    "                        \"AttributeNames\": ['source-ref', labeling_job_name]\n",
    "                    }\n",
    "                },\n",
    "                \"ContentType\": \"application/x-recordio\",\n",
    "                \"RecordWrapperType\": \"RecordIO\",\n",
    "                \"CompressionType\": \"None\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Now we create the SageMaker training job.\n",
    "client = boto3.client(service_name='sagemaker')\n",
    "client.create_training_job(**training_params)\n",
    "\n",
    "# Confirm that the training job has started\n",
    "status = client.describe_training_job(TrainingJobName=training_job_name)['TrainingJobStatus']\n",
    "print('Training job current status: {}'.format(status))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the progess of the training job, you can refresh the console or repeatedly evaluate the following cell. When the training job status reads `'Completed'`, move on to the next part of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "client = boto3.client('sagemaker')\n",
    "\n",
    "training_info = client.describe_training_job(TrainingJobName=training_job_name)\n",
    "\n",
    "print(\"Training job status: \", training_info['TrainingJobStatus'])\n",
    "print(\"Secondary status: \", training_info['SecondaryStatus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='review_training'></a>\n",
    "\n",
    "## Review of Training Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's create the SageMaker model out of model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "model_name = training_job_name + '-model' + timestamp\n",
    "\n",
    "training_image = training_info['AlgorithmSpecification']['TrainingImage']\n",
    "model_data = training_info['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "primary_container = {\n",
    "    'Image': training_image,\n",
    "    'ModelDataUrl': model_data,\n",
    "}\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "create_model_response = client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "endpoint_config_name = training_job_name + '-epc' + timestamp\n",
    "endpoint_config_response = client.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.t2.medium',\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print('Endpoint configuration name: {}'.format(endpoint_config_name))\n",
    "print('Endpoint configuration arn:  {}'.format(endpoint_config_response['EndpointConfigArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Endpoint\n",
    "\n",
    "The next cell creates an endpoint that can be validated and incorporated into production applications. This takes about 10 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "endpoint_name = training_job_name + '-ep' + timestamp\n",
    "print('Endpoint name: {}'.format(endpoint_name))\n",
    "\n",
    "endpoint_params = {\n",
    "    'EndpointName': endpoint_name,\n",
    "    'EndpointConfigName': endpoint_config_name,\n",
    "}\n",
    "endpoint_response = client.create_endpoint(**endpoint_params)\n",
    "print('EndpointArn = {}'.format(endpoint_response['EndpointArn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = response['EndpointStatus']\n",
    "print('EndpointStatus = {}'.format(status))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "test_images = glob.glob('images/test/*')\n",
    "print(*test_images, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_to_bbox_data(image_path, prediction):\n",
    "    class_id, confidence, xmin, ymin, xmax, ymax = prediction\n",
    "    width, height = Image.open(image_path).size\n",
    "    bbox_data = {'class_id': class_id,\n",
    "               'height': (ymax-ymin)*height,\n",
    "               'width': (xmax-xmin)*width,\n",
    "               'left': xmin*width,\n",
    "               'top': ymin*height}\n",
    "    return bbox_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "runtime_client = boto3.client('sagemaker-runtime')\n",
    "def get_predictions_for_img(runtime_client, endpoint_name, img_path):\n",
    "    with open(img_path, 'rb') as f:\n",
    "        payload = f.read()\n",
    "        payload = bytearray(payload)\n",
    "\n",
    "    response = runtime_client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                       ContentType='application/x-image', \n",
    "                                       Body=payload)\n",
    "\n",
    "    result = response['Body'].read()\n",
    "    result = json.loads(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "# wait until the status has changed\n",
    "client.get_waiter('endpoint_in_service').wait(EndpointName=endpoint_name)\n",
    "endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = endpoint_response['EndpointStatus']\n",
    "if status != 'InService':\n",
    "    raise Exception('Endpoint creation failed.')\n",
    "    \n",
    "for test_image in test_images:\n",
    "    result = get_predictions_for_img(runtime_client, endpoint_name, test_image)\n",
    "    confidence_threshold = .03\n",
    "    best_n = 1\n",
    "    # display the best n predictions with confidence > confidence_threshold\n",
    "    predictions = [prediction for prediction in result['prediction'] if prediction[1] > confidence_threshold]\n",
    "    predictions.sort(reverse=True, key = lambda x: x[1])\n",
    "    bboxes = [prediction_to_bbox_data(test_image, prediction) for prediction in predictions[:best_n]]\n",
    "    \n",
    "    for prediction in predictions[:best_n]:\n",
    "        prediction_list = sorted(prediction, reverse = True)\n",
    "    for item in sorted(prediction, reverse = True):\n",
    "        if item == 1.0:\n",
    "            try:\n",
    "                prediction_list.remove(item)\n",
    "            except:\n",
    "                print(\"\")\n",
    "    conf_precision3 = str(prediction_list[0])[0] + str(prediction_list[0])[1] + str(prediction_list[0])[2] + str(prediction_list[0])[3]\n",
    "    \n",
    "    show_annotated_image(test_image, bboxes, conf_precision3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='model_tuning'></a>\n",
    "## Model Tuning\n",
    "\n",
    "When you configured the training job you needed to add many hyperparameters that affect the performance of the algorithm and the quality of the resulting model. But how do you pick the right hyperparameters?\n",
    "\n",
    "If you have experience with the specific algorithm and understand the innerworkings of it, you may already have a good sense of appropriate values. But even then, it's impossible to know the exact best value of each hyperparameter. Often you can zero in on the best values by trying many different combination of values, effectively searching in the hyperparameter space. SageMaker makes this extremely easy with the Model Tuning feature, also known as Hyperparameter Optimization (or HPO). With Model Tuning you simply decide which of the hyperparameters you are not sure about and specify the range of values for each that SageMaker needs to explore. Let's see again how this can be accomplished via the console.\n",
    "\n",
    "This is a placeholder for future exploration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='model_optimization'></a>\n",
    "## Model Optimization\n",
    "\n",
    "In order to deploy the MXNet model to AWS DeepLens, the model artifacts must be optimized. This currently involves running a depricated deploy.py script which has recently been removed from the mxnet-incubator source. We will clone mxnet-incubator to the notebook, then checkout an earlier revision.\n",
    "\n",
    "Next we somewhat ungracefully unpack the model, rename files, and optimize the model. We then repack the mdel into a new file and upload to s3 where we can import it into a DeepLens model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Git cloning should be wrapped in an if statement that determines if the directory already exists, or moved to a Lifecycle script ###\n",
    "!cd lib && git clone https://github.com/apache/incubator-mxnet.git\n",
    "!aws s3 cp s3://$s3_output_path/$training_job_name/output/model.tar.gz working/model/model-orig.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This command rolls back to the commit before they removed the deploy.py script. ###\n",
    "!cd lib/incubator-mxnet && git checkout 26f44b71d8de84bbc88af496ae0aeb7ce535312d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Unpack the model and move the files into a tmp directory ###\n",
    "!cd working/model/tmp && tar xvfpz ../model.tar.gz.orig\n",
    "!cd working/model/tmp && mv model_algo_1-0000.params model_resnet50_300-0100.params\n",
    "!cd working/model/tmp && mv model_algo_1-symbol.json model_resnet50_300-symbol.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extract the model artifacts and optimize them for DeepLens ###\n",
    "!cd working/model/tmp && python3 ../../../lib/incubator-mxnet/example/ssd/deploy.py --network resnet50 --data-shape 300 --num-class 2 --epoch 100 --prefix model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pack the model bak up into the model directory ###\n",
    "!cd working/model/tmp && mv model_resnet50_300-0100.params model_resnet50_300-0000.params\n",
    "!cd working/model/tmp && tar cvfz ../model.tar.gz model_resnet50_300-0000.params model_resnet50_300-symbol.json hyperparams.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd working/model && aws s3 cp model.tar.gz $s3_output_path/$training_job_name/output/model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='cleanup'></a>\n",
    "## Cleanup\n",
    "\n",
    "Delete the endpoint to stop incurring costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
